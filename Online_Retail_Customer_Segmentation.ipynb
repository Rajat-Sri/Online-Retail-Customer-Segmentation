{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rajat-Sri/Online-Retail-Customer-Segmentation/blob/main/Online_Retail_Customer_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - **Online Retail Customer Segmentation**\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised Machine Learning(Clustering)\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 -** Rajat Srivastava"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the summary here within 500-600 words."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -** "
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/Rajat-Sri/Online-Retail-Customer-Segmentation"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### In this project, we are tasked to identify major customer segments on a transnational data set which contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail.The company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing required libraries\n",
        "import numpy as np\n",
        "# To handle the dataset\n",
        "import pandas as pd\n",
        "\n",
        "# For plots and visualizations\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits import mplot3d\n",
        "%matplotlib inline\n",
        "from yellowbrick.cluster import SilhouetteVisualizer\n",
        "\n",
        "# For getting optimal number of clusters in hierarchical clustering\n",
        "from scipy.cluster.hierarchy import dendrogram,linkage\n",
        "\n",
        "# To scale the data\n",
        "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
        "\n",
        "# metrics to evaluate the clusters\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Clustering alorithms\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
        "\n",
        "# Display utilities\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "# activating DND to disregard the warnings by goiing silent mode\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# setting default parameters for the plots\n",
        "plt.rcParams[\"figure.figsize\"] = (10,5)\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the dataset\n",
        "\n",
        "dataset = pd.read_csv('/content/drive/MyDrive/Almabetter/Capstone Projects/Capstone 4/Online Retail.xlsx - Online Retail.csv')"
      ],
      "metadata": {
        "id": "t5lLcPnd4VoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "\n",
        "dataset.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "\n",
        "dataset.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "\n",
        "len(dataset[dataset.duplicated()])"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "\n",
        "missing = dataset.columns[dataset.isnull().any()].tolist()\n",
        "\n",
        "print('Missing dataset Count')\n",
        "print(dataset[missing].isnull().sum().sort_values(ascending = False))\n",
        "print('--'*12)\n",
        "print('Missing dataset Percentage')\n",
        "print(round(dataset[missing].isnull().sum().sort_values(ascending = False)/len(dataset)*100,2))\n",
        "     "
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "\n",
        "# Checking Null Value by plotting Heatmap\n",
        "sns.heatmap(dataset.isnull(), cbar=False)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The dataset has 541,909 rows and 8 columns.\n",
        "\n",
        "- The columns are Invoice No, Stock Code, Description, Quantity, Invoice Date, Unit Price, Customer ID, and Country.\n",
        "\n",
        "- The dataset contains both numerical and categorical data types.\n",
        "\n",
        "- There are missing values in the Customer ID and Description columns. Specifically, there are 135,080 missing values in the Customer ID column and 1,454 missing values in the Description column.\n",
        "\n",
        "- There are 5,268 duplicate values in the dataset.\n",
        "\n",
        "- The Invoice Date column is stored as an object data type and would need to be converted to a datetime data type for time-series analysis.\n",
        "\n",
        "- The Unit Price column is stored as a float data type, which suggests that the prices may contain decimals.\n",
        "\n",
        "- The country column is stored as an object data type, which suggests that there may be multiple countries in the dataset.\n",
        "\n",
        "- The missing values in the Customer ID column may indicate that some purchases were made by customers who did not provide their ID or were not registered.\n",
        "\n",
        "- The missing values in the Description column may indicate that some products did not have a description or the description was not recorded properly."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "\n",
        "dataset.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "\n",
        "dataset.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#### <b>Attribute Information: </b>\n",
        "\n",
        "* ### **InvoiceNo**: Invoice number. Nominal, a 6-digit integral number uniquely assigned to each transaction. If this code starts with letter 'c', it indicates a cancellation.\n",
        "* ### **StockCode**: Product (item) code. Nominal, a 5-digit integral number uniquely assigned to each distinct product.\n",
        "* ### **Description**: Product (item) name. Nominal.\n",
        "* ### **Quantit**y: The quantities of each product (item) per transaction. Numeric.\n",
        "* ### **InvoiceDate**: Invoice Date and time. Numeric, the day and time when each transaction was generated.\n",
        "* ### **UnitPrice**: Unit price. Numeric, Product price per unit in sterling.\n",
        "* ### **CustomerID**: Customer number. Nominal, a 5-digit integral number uniquely assigned to each customer.\n",
        "* ### **Country**: Country name. Nominal, the name of the country where each customer resides."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "\n",
        "for i in dataset.columns.tolist():\n",
        "  print(\"No. of unique values in \",i,\"is\",dataset[i].nunique(),\".\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique countries name.\n",
        "\n",
        "#creating a column list \n",
        "categorical_variables = ['Country']\n",
        "\n",
        "#checking the unique values\n",
        "for col in categorical_variables:\n",
        "  print(f'Unique values for {col}: {dataset[col].unique()}')"
      ],
      "metadata": {
        "id": "5fWyTTJry61d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# Missing data counts and percentage\n",
        "missing = dataset.columns[dataset.isnull().any()].tolist()\n",
        "\n",
        "print('Missing Data Count')\n",
        "print(dataset[missing].isnull().sum().sort_values(ascending = False))\n",
        "print('--'*12)\n",
        "print('Missing Data Percentage')\n",
        "print(round(dataset[missing].isnull().sum().sort_values(ascending = False)/len(dataset)*100,2))"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Data with no customer assignment is of no use to us, because we can'y form clusters without customer ID.\n",
        "- So we will be removing such rows from our dataset."
      ],
      "metadata": {
        "id": "UF6eLLGc0DFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping the rows with nulls\n",
        "dataset.dropna(subset=['CustomerID','Description'], inplace=True)\n",
        "\n",
        "# New Shape\n",
        "dataset.shape"
      ],
      "metadata": {
        "id": "KJb8Wbodz9Zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking duplicates\n",
        "\n",
        "print(len(dataset[dataset.duplicated()]))"
      ],
      "metadata": {
        "id": "auDvAPmIz9i0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping duplicate rows\n",
        "dataset.drop_duplicates(inplace=True)\n",
        "\n",
        "# New Shape\n",
        "dataset.shape"
      ],
      "metadata": {
        "id": "dSUcYQzDz9t3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Randomly assigning Customer IDs can make it difficult to track customer behavior over time, such as their purchase history, preferences, and interactions with the company. This can make it challenging to personalize the customer experience and provide targeted marketing and promotional campaigns."
      ],
      "metadata": {
        "id": "yxBkOaaxUPK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checking null counts and datatype in each column\n",
        "dataset.info()"
      ],
      "metadata": {
        "id": "6knDB3gGz9wU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating new features from the datetime column InvoiceDate\n",
        "\n",
        "#creating features from the date for better data visualization\n",
        "\n",
        "dataset['InvoiceDate'] = pd.to_datetime(dataset['InvoiceDate']) # converting from object to datetime format\n",
        "dataset[\"year\"]  = dataset[\"InvoiceDate\"].apply(lambda x: x.year)\n",
        "dataset['Month'] = dataset['InvoiceDate'].apply(lambda x: x.month_name())\n",
        "dataset['Day']   = dataset['InvoiceDate'].apply(lambda x: x.day_name())\n",
        "dataset[\"hour\"]  = dataset[\"InvoiceDate\"].apply(lambda x: x.hour)"
      ],
      "metadata": {
        "id": "dLp4hoBvz9zJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a new feature 'TotalAmount' by multiplying Quantity and UnitPrice\n",
        "dataset['TotalAmount'] = dataset['Quantity']*dataset['UnitPrice']"
      ],
      "metadata": {
        "id": "tUii1g1oz92l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head(1)"
      ],
      "metadata": {
        "id": "hsoSn8Rg710f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Manipulations**\n",
        "\n",
        "- Missing values were removed from the CustomerID and Description columns, since the missing values were significant in number (135,080 and 1,454, respectively). This was likely done to avoid any potential biases or errors in the analysis.\n",
        "\n",
        "- Duplicate values were removed from the dataset to ensure that each observation was unique and not counted multiple times. This was likely done to avoid any overestimation of the data.\n",
        "\n",
        "- New features were created using the Invoice Date column. Specifically, new columns were created for year, month, day, and hour to allow for more granular analysis of the data over time. This was likely done to identify any trends or patterns in customer behavior or sales over time.\n",
        "\n",
        "- A new feature called TotalAmount was created by multiplying the Quantity and UnitPrice columns. This was likely done to capture the total revenue generated by each transaction.\n",
        "\n",
        "\n",
        "\n",
        "**Insights from dataset** - \n",
        "\n",
        "Based on the given information, here are some insights that can be derived:\n",
        "\n",
        "- The Quantity column has a mean value of 9.55 and a standard deviation of 218.08, which indicates that the quantity of items purchased varies greatly across the dataset. The negative minimum value (-80,995) suggests that there may be some refunds or returns included in the dataset.\n",
        "\n",
        "- The UnitPrice column has a mean value of 4.61 and a standard deviation of 96.76, which indicates that the prices of items purchased also vary greatly across the dataset. The negative minimum value (-11,062.06) suggests that there may be some refunds or returns included in the dataset.\n",
        "\n",
        "- The CustomerID column has a mean value of 15,287.69 and a standard deviation of 1,713.60. This suggests that the majority of customers have an ID in the range of 13,574 to 16,002. However, there are missing values in this column, which indicates that some customers did not provide their ID or were not registered.\n",
        "\n",
        "- The maximum value for the Quantity column is 80,995, while the maximum value for the UnitPrice column is 38,970. These values may indicate some outliers or errors in the data, and should be further investigated.\n",
        "\n",
        "- The quartile ranges for the Quantity and UnitPrice columns suggest that most purchases were relatively small in quantity and price, with the majority of transactions having a quantity of 10 items or less and a unit price of 4.13 or less.\n",
        "\n",
        "Overall, this information provides some basic statistics on the Quantity, UnitPrice, and CustomerID columns, which can help to understand the general characteristics of the data. However, further analysis and exploration is needed to gain more insights into the dataset."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1 - Sales over an year."
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "\n",
        "#Sales trends over years\n",
        "sales_over_years = dataset.groupby(['year'])['TotalAmount'].sum().reset_index() # grouping by year\n",
        "sales_over_years = sales_over_years.sort_values(by = ['TotalAmount'], ascending = False) # soring data by sales in descending order\n",
        "print(sales_over_years)\n",
        "\n",
        "#Visualizing using line graph\n",
        "dataset.groupby('year')[\"TotalAmount\"].sum().plot.line(title='Sales over years',figsize=(10,5), legend=True,color='r') \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We have used a line graph to visualize the sales trends over the years. A line graph is a suitable type of chart to visualize trends over time, where we can see how the values change over time."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- we can observe that the total sales amount has increased 14 times from the year 2010 to 2011. This indicates that there has been a significant increase in sales over the years, which can be due to various reasons like marketing strategies, increase in customer base, or introduction of new products"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The gained insights can help create a positive business impact as it shows that the company's sales are growing year by year. This can help the business to identify the successful strategies that have contributed to the growth and capitalize on them to further increase sales in the future. "
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2 - Monthly sales over the year."
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "\n",
        "# Define custom sort order for months\n",
        "month_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
        "\n",
        "# Group sales by month and calculate total sales for each month\n",
        "sales_month = dataset.groupby('Month')['TotalAmount'].sum().reset_index()\n",
        "\n",
        "# Convert the 'Month' column to categorical data type with custom sort order\n",
        "sales_month['Month'] = pd.Categorical(sales_month['Month'], categories=month_order, ordered=True)\n",
        "\n",
        "# Sort the data by the 'Month' column\n",
        "sales_month = sales_month.sort_values('Month')\n",
        "print(sales_month)\n",
        "\n",
        "#Visualize using line graph with markers\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(sales_month['Month'], sales_month['TotalAmount'], marker='o', color='r')\n",
        "plt.title('Sales over Months')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Total sales amount')\n",
        "plt.xticks(sales_month['Month'], rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_FcjFCsmlOPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Line graph is used to visualize the trend of sales over the months in a year. It helps in identifying the months where sales are high and low, and also helps in identifying the seasonality of the sales."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- From the chart, we can see that the sales tend to spike in the months of November and December, indicating a higher demand during the holiday season. There is also a noticeable dip in sales during the month of February, which could be due to a lull in demand after the holiday season. Overall, the chart gives us a good understanding of the seasonality of sales over the two-year period."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The insights gained from the chart can help in forecasting sales for the upcoming years and in planning marketing and sales strategies accordingly. The business can focus on increasing the stock during the holiday season and promoting sales during other months to increase revenue. Overall, the insights gained from the chart can have a positive impact on the business."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3 - Sales over different days of the week."
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "\n",
        "# Define custom sort order for days of the week\n",
        "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
        "\n",
        "# Group sales by day of the week and calculate total sales for each day\n",
        "all_week_sales = dataset.groupby(['Day'])['TotalAmount'].sum().reset_index()\n",
        "\n",
        "# Convert the 'Day' column to categorical data type with custom sort order\n",
        "all_week_sales['Day'] = pd.Categorical(all_week_sales['Day'], categories=day_order, ordered=True)\n",
        "\n",
        "# Sort the data by the 'Day' column\n",
        "all_week_sales = all_week_sales.sort_values('Day')\n",
        "print(all_week_sales)\n",
        "\n",
        "# Visualizing using line graph\n",
        "all_week_sales.plot(x='Day', y='TotalAmount', kind='line', title='Day of week and Sales', figsize=(10,5), legend=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nke_CEvDnBtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Line graphs are commonly used to show trends over time or across categories. In this case, we are showing the trend of total sales for each day of the week."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- From the chart, we can see that Thursday has the highest total sales followed by Tuesday and Wednesday. Sunday has the lowest total sales."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- This insight can help businesses to schedule promotions and sales events on the days of the week when sales are typically higher. For example, a business can offer a promotion on Thursdays to attract more customers and increase sales.\n"
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4 - Top 10 values for each variable."
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "\n",
        "# Plotting top values based on frequency in each column\n",
        "target = ['StockCode', 'Description','UnitPrice', 'CustomerID', 'Country',\n",
        "          'year', 'Month','Day','hour']\n",
        "\n",
        "plt.figure(figsize=(20,25), dpi=90)\n",
        "for n,col in enumerate(target):\n",
        "  plt.subplot(5, 2, n+1)\n",
        "  temp = dataset[col].value_counts().reset_index().head(10)\n",
        "  temp.rename(columns={'index': col, col:'count'}, inplace=True)\n",
        "  sns.barplot(x=col ,y='count', data=temp).set(title=col.title())\n",
        "  plt.xticks(rotation=20,ha='right')\n",
        "  plt.tight_layout()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Bar charts are one of beat ways to show segments of information. Vertical/Horizontal bar charts are useful to compare different categorical or discrete variables, such as age groups, classes, schools, etc., as long as there are not too many categories to compare."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Most Customers are from United Kingdom. Considerable number of customers are also from Germany, France, EIRE and Spain.\n",
        "- There are no orders placed on Saturdays. Looks like it's a non working day for the retailer.\n",
        "- Most of the customers have purchased the products in the month of November, October, December and September. Less number of customers have purchased the gifts in the month of April, January and February.\n",
        "4. Most of the customers have purchased the items in Afternoon timings.\n",
        "5. WHITE HANGING HEART T-LIGHT HOLDER, REGENCY CAKESTAND 3 TIER, JUMBO BAG RED RETROSPOT are the most ordered products"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We know which countaries, products and timings people prefer.Retailer can take advantage of these information for creating positive impact for their business."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5 - Countaries with highest sales."
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "\n",
        "# Most sales from top 5 countries\n",
        "\n",
        "country_sales = dataset.groupby(\"Country\").sum()[\"TotalAmount\"].reset_index().sort_values(\"TotalAmount\",ascending=False)\n",
        "top_5_countries = country_sales.head(5)\n",
        "top_5_sales = top_5_countries['TotalAmount'].sum()\n",
        "top_5_countries.loc[5] = ['Others', country_sales['TotalAmount'].sum() - top_5_sales]\n",
        "print(top_5_countries)\n",
        "\n",
        "# Visualizing top 5 countries based on total sales\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.title(\"Top 5 Countries based on Sales\")\n",
        "plt.pie(top_5_countries['TotalAmount'], labels=top_5_countries['Country'], autopct='%1.1f%%')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sqrjE7BzphKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The chart used here is a pie chart, which is a circular chart divided into slices to represent data. In this case, it is used to show the percentage of total sales contributed by the top 5 countries and \"Others\" category."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The insights gained from the chart are that the United Kingdom is the top contributor to sales with 81.5% followed by the Netherlands with 3.4%, EIRE with 3.0%, Germany with 2.7%, and France with 2.4%. The remaining countries contribute to 7% of the total sales."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- These insights can help businesses understand which countries are the biggest contributors to their sales and focus their marketing and sales efforts on those countries. They can also help businesses identify potential growth opportunities in countries that are not currently in the top 5 but have potential for growth. Overall, this can lead to a positive business impact by improving sales and profitability."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6 - Countaries with least sales."
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "\n",
        "# Least sales from these countries\n",
        "country_sales = dataset.groupby(\"Country\").sum()[\"TotalAmount\"].reset_index().sort_values(\"TotalAmount\", ascending=True).head(5)\n",
        "country_sales.rename(columns={'TotalAmount': 'Sales_Count'}, inplace=True)\n",
        "print(country_sales)\n",
        "\n",
        "# Visualizing top countries based on total sales \n",
        "plt.figure(figsize=(10, 5), dpi=90)\n",
        "plt.xticks(rotation=20, ha='right')\n",
        "plt.title(\"Top 5 Countries with Least Sales\")\n",
        "sns.barplot(data=country_sales, x=\"Country\", y=\"Sales_Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NJBPPoIytBSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Bar charts are one of best ways to show segments of information.Bar graph was used because it is effective in comparing the sales values of different categories"
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The graph shows that Saudi Arabia has the least sales count among all the countries in the dataset, followed by Bahrain, Czech Republic, RSA, and Brazil."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- From this chart, we can see the countries that need more attention in terms of sales and marketing strategies to improve their performance. Focusing on these countries may help the business increase its revenue and expand its customer base. Hence, the insights gained from this chart can potentially have a positive business impact."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7 - Countaries with highest order quantity."
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "\n",
        "# Countrywise average item purchases\n",
        "country_quantity = dataset.groupby(\"Country\").mean()[\"Quantity\"].reset_index().sort_values(\"Quantity\",ascending=False)\n",
        "top_5_countries = country_quantity.head(5)\n",
        "top_5_quantity = top_5_countries['Quantity'].sum()\n",
        "top_5_countries.loc[5] = ['Others', country_quantity['Quantity'].sum() - top_5_quantity]\n",
        "print(top_5_countries)\n",
        "\n",
        "# Visualizing top countries based on average item purchases \n",
        "plt.figure(figsize=(10,8))\n",
        "plt.title(\"Top 5 Countries based on Average Quantity\")\n",
        "plt.pie(top_5_countries['Quantity'], labels=top_5_countries['Country'], autopct='%1.1f%%')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DNQUT1vfuPLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A pie chart is a suitable choice in this case because it helps to visualize the proportion of each category in a clear and concise manner."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- From the chart, we can see that the Netherlands has the highest average item purchases, followed by Sweden, Japan, Australia, and Singapore. The \"Others\" category has a relatively low average quantity compared to the top 5 countries. - Therefore, the chart provides insights into the countries where the business can potentially focus its efforts to increase B2B sales as they are doing most of bulk ordering."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The gained insights can potentially help create a positive business impact by informing the business on where to focus its resources and marketing efforts to increase sales. For example, if the business has been neglecting the Netherlands market, the chart indicates that it might be a good idea to invest more in marketing and sales in that region."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8 - Product with High quantity orders."
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "\n",
        "# quantity wise item purchases\n",
        "product_quantity = dataset.groupby(\"Description\").sum()[\"Quantity\"].reset_index().sort_values(\"Quantity\",ascending=False).head(5)\n",
        "print(product_quantity)\n",
        "\n",
        "# Visualizing top and bottom 10 products based on purchase quantity\n",
        "plt.figure(figsize=(20,5), dpi=90)\n",
        "plt.subplot(1,2,1)\n",
        "plt.xticks(rotation=20,ha='right')\n",
        "plt.title(\"Product with High quantity orders\")\n",
        "sns.barplot(data=product_quantity,x=\"Description\",y=\"Quantity\")"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We used a bar plot in this visualization because it is a good way to compare the quantity of different products."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Decoration products and jewellery items are mostly ordered in bulk quantity."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The insights gained from this chart are that these top 5 products are very popular and have high purchase quantities, which indicates that they are in high demand among customers. This information can be useful for the business to focus on these popular products and ensure they are always in stock to meet customer demand. Additionally, the business can explore ways to promote these products to potentially increase their sales even further."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9 - Product that made most of the revenue."
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "\n",
        "# Amount wise item purchases\n",
        "product_price = dataset.groupby(\"Description\").sum()[\"TotalAmount\"].reset_index().sort_values(\"TotalAmount\",ascending=False).head(5)\n",
        "print(product_price)\n",
        "\n",
        "# Visualizing top products based on amount\n",
        "plt.figure(figsize=(20,5), dpi=90)\n",
        "plt.subplot(1,2,1)\n",
        "plt.xticks(rotation=20,ha='right')\n",
        "plt.title(\"Product that made most of the revenue\")\n",
        "sns.barplot(data=product_price,x=\"Description\",y=\"TotalAmount\")"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We have used a bar plot to visualize the top products based on the amount of revenue they have generated."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The \"Regency Cakestand 3 Tier\" is the top-selling product in terms of generating the most revenue, followed by \"White Hanging Heart T-Light Holder\" and \"Jumbo Bag Red Retrospot\".\n",
        "- \"Postage\" is also one of the top-selling products in terms of generating revenue, which indicates that shipping and handling costs are an important part of the business.\n",
        "- The top-selling products based on revenue are different from the top-selling products based on quantity. This indicates that the business should focus not only on selling more products but also on selling high-value products to increase revenue."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The gained insights can definitely help in creating a positive business impact by providing valuable information on the products that are generating the most revenue. The business can use this information to make informed decisions about inventory management, product pricing, and marketing strategies to increase revenue and profitability."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10 - Product with large customer base."
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "\n",
        "# customer wise item purchases\n",
        "product_customer = dataset.groupby(\"Description\").nunique()[\"CustomerID\"].reset_index().sort_values(\"CustomerID\",ascending=False).head(5)\n",
        "product_customer.rename(columns={'CustomerID': 'Customer_Count'}, inplace=True)\n",
        "print(product_customer)\n",
        "\n",
        "# Visualizing top products based on customers\n",
        "plt.figure(figsize=(20,5), dpi=90)\n",
        "plt.subplot(1,2,1)\n",
        "plt.xticks(rotation=20,ha='right')\n",
        "plt.title(\"Product with large customer base\")\n",
        "sns.barplot(data=product_customer,x=\"Description\",y=\"Customer_Count\")"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We have used a bar plot to visualize the top products based on the number of customers who have purchased them. The bar plot effectively compares the customer count of each product in a clear and concise manner."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Products related to patries and decoration are more in demand."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Knowing the top products with a large customer base can help the business in several ways, such as:\n",
        "\n",
        "- These products could be marketed more to increase their sales and revenue.\n",
        "- The business could develop new products similar to these popular items to attract more customers.\n",
        "- The business could focus on improving the quality of these popular products to maintain and grow their customer base."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11 - Customer with High cancellations."
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "\n",
        "# Sales less than 0 represents cancellation or return\n",
        "cancellations = dataset[dataset['Quantity'] < 0]\n",
        "print(f'There are {len(cancellations)} transactions for the returns')\n",
        "\n",
        "# Checking the number of cancellations by each customer. \n",
        "customer_cancellations = cancellations.groupby('CustomerID').count()['InvoiceNo'].reset_index().sort_values(\"InvoiceNo\",ascending=False).head(5)\n",
        "customer_cancellations.rename(columns={'InvoiceNo': 'Cancellations'}, inplace=True)\n",
        "print(customer_cancellations)\n",
        "\n",
        "# Visualizing top customers based on cancellations \n",
        "plt.figure(figsize=(20,5), dpi=90)\n",
        "plt.subplot(1,2,1)\n",
        "plt.xticks(rotation=20,ha='right')\n",
        "plt.title(\"customer with High cancellations\")\n",
        "sns.barplot(data=customer_cancellations,x=\"CustomerID\",y=\"Cancellations\")\n"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We have used a bar plot to visualize the top customers based on cancellations. The bar plot is useful for comparing the number of cancellations by different customers."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- From the chart, we can see that the customer with ID 14911.0 has the highest number of cancellations, followed by customers with IDs 17841.0, 17511.0, 15311.0, and 12607.0."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The insight gained from the chart is that some customers have a higher tendency to cancel or return their purchases than others. This can help the business identify these customers and investigate the reasons for their cancellations. It can also help the business to better manage their inventory and avoid stockouts by having a more accurate estimation of demand.\n",
        "\n",
        "Overall, the gained insights could potentially have a positive business impact by improving customer satisfaction and reducing costs associated with cancellations and returns."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12 - Customer with Highest order quantity"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the number of orders by each customer. \n",
        "customer_orders = dataset.groupby('CustomerID').count()['InvoiceNo'].reset_index().sort_values(\"InvoiceNo\",ascending=False).head(5)\n",
        "customer_orders.rename(columns={'InvoiceNo': 'order quantity'}, inplace=True)\n",
        "print(customer_orders)\n",
        "\n",
        "# Visualizing top customers based on orders \n",
        "plt.figure(figsize=(20,5), dpi=90)\n",
        "plt.subplot(1,2,1)\n",
        "plt.xticks(rotation=20,ha='right')\n",
        "plt.title(\"customer with Highest order quantity\")\n",
        "sns.barplot(data=customer_orders,x=\"CustomerID\",y=\"order quantity\")"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We have used a bar plot to visualize the number of orders made by each customer. The bar plot is useful in this scenario as it displays the order quantity for each customer in a clear and concise manner."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The insight gained from the chart is that the top 5 customers with the highest order quantity have placed significantly more orders than other customers. This information is helpful in identifying the top customers who are contributing to the majority of sales and can help the business to focus on retaining these customers by providing better service, personalized offers, or other incentives to maintain their loyalty."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Overall, the insights gained from this chart can have a positive business impact by enabling the business to target its resources and efforts towards retaining its most valuable customers."
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13 - Products with High cancellations"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code\n",
        "\n",
        "# Checking the number of cancellations product wise. \n",
        "product_cancellations = cancellations.groupby('Description').count()['InvoiceNo'].reset_index().sort_values(\"InvoiceNo\",ascending=False).head(5)\n",
        "product_cancellations.rename(columns={'InvoiceNo': 'Cancellations'}, inplace=True)\n",
        "print(product_cancellations)\n",
        "\n",
        "# Visualizing top countries based on cancellations \n",
        "plt.figure(figsize=(20,5), dpi=90)\n",
        "plt.subplot(1,2,1)\n",
        "plt.xticks(rotation=20,ha='right')\n",
        "plt.title(\"Products with High cancellations\")\n",
        "sns.barplot(data=product_cancellations,x=\"Description\",y=\"Cancellations\")"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We have used a bar plot to visualize the top products with the highest number of cancellations. The bar plot is an effective way to compare the number of cancellations between different products."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Regency cakestand,jam making set, discounted products have higher chance of getting returned.\n",
        "- There could be many reasons why customers are returning or cancelling products, such as a defect in the product or a mismatch in customer expectations. It would be necessary to investigate further and gather more data to determine the exact cause of the cancellations or returns."
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- These insights can help the business to identify which products are more likely to be canceled or returned by customers. By analyzing the reasons for cancellations and taking necessary actions, the business can improve its customer satisfaction and reduce the number of returns. It can also help to adjust the inventory levels and plan the procurement accordingly to minimize the potential loss due to cancellations."
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking relation between  features using correlation heatmap\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.heatmap(dataset.corr(), cmap=\"coolwarm\", annot=True)\n"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlation heatmaps is used to find potential relationships between variables and to understand the strength of these relationships. In addition, correlation plots helps to identify outliers and to detect linear and nonlinear relationships as well."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- From basic observation, if we leave the variables which we created for data visualization, there is no major multicollinarity associated which needs to be corrected for now."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Research Hypothesis:\n",
        "- Null hypothesis: There is no significant difference in the total amount spent by customers in different countries.\n",
        "- Alternative hypothesis: There is a significant difference in the total amount spent by customers in different countries."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "# Perform one-way ANOVA\n",
        "result = stats.f_oneway(*[group[\"TotalAmount\"] for name, group in dataset.groupby(\"Country\")])\n",
        "\n",
        "# Print F-statistic and p-value\n",
        "print(\"F-statistic:\", result.statistic)\n",
        "print(\"p-value:\", result.pvalue)\n",
        "\n",
        "# Interpret result\n",
        "if result.pvalue < 0.05:\n",
        "    print(\"We reject the null hypothesis and accept the alternative hypothesis. There is a significant difference in the total amount spent by customers in different countries.\")\n",
        "else:\n",
        "    print(\"We accept null hypothesis and reject alternate hypothesis. There is no significant difference in the total amount spent by customers in different countries.\")"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In this case, the obtained F-statistic is 6.06, which indicates that there is some difference in the means of the total amount spent by customers in different countries.\n",
        "- The p-value is 5.88e-28, which is very small (much less than the commonly used threshold of 0.05), indicating that this difference is unlikely to be due to chance alone. \n",
        "Therefore, we can reject the null hypothesis that there is no significant difference in the total amount spent by customers in different countries, and accept the alternative hypothesis that there is a significant difference."
      ],
      "metadata": {
        "id": "N-idHOHnKfhB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  We have used the one-way ANOVA (Analysis of Variance) statistical test to compare the mean total amount spent by customers in different countries."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We chose ANOVA because we are interested in comparing the means of multiple groups (countries) at once, and ANOVA is an appropriate statistical test for this purpose."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Research Hypothesis:\n",
        "- Null hypothesis: There is no difference in the average quantity of items purchased by customers from different countries.\n",
        "- Alternative hypothesis: There is a significant difference in the average quantity of items purchased by customers from different countries."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Perform one-way ANOVA\n",
        "result = stats.f_oneway(*[group[\"Quantity\"] for name, group in dataset.groupby(\"Country\")])\n",
        "\n",
        "# Print F-statistic and p-value\n",
        "print(\"F-statistic:\", result.statistic)\n",
        "print(\"p-value:\", result.pvalue)\n",
        "\n",
        "\n",
        "# Interpret result\n",
        "if result.pvalue < 0.05:\n",
        "    print(\"We reject the null hypothesis and accept the alternative hypothesis. There is a significant difference in the average quantity of items purchased by customers from different countries.\")\n",
        "else:\n",
        "    print(\"We accept null hypothesis and reject alternate hypothesis. There is no significant difference in the average quantity of items purchased by customers from different countries.\")\n"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- The F-statistic is a test statistic used in ANOVA to determine if there is a significant difference between the means of the groups being compared.\n",
        "\n",
        " **A larger F-statistic indicates a larger difference between the means of the groups. In our case, the F-statistic is 8.901**.\n",
        "\n",
        "- The p-value is a measure of the evidence against the null hypothesis. A small p-value indicates strong evidence against the null hypothesis, suggesting that there is a significant difference between the means of the groups being compared. In contrast, a large p-value indicates weak evidence against the null hypothesis, suggesting that there is not a significant difference. \n",
        "\n",
        "  **In yourour case, the p-value is 2.615e-47, which is very small (much less than 0.05), indicating strong evidence against the null hypothesis.**\n",
        "\n",
        "Therefore, based on the obtained F-statistic and p-value, we can reject the null hypothesis and conclude that there is a significant difference in the average quantity of items purchased by customers from different countries."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We have used the **one-way ANOVA (Analysis of Variance) statistical test** to compare the mean quantity of items purchased by customers from different countries.\n",
        "- We chose ANOVA because we are interested in comparing the means of multiple groups (countries) at once, and ANOVA is an appropriate statistical test for this purpose. "
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Research Hypothesis:\n",
        "- Null Hypothesis (H0): The mean total amount spent by customers in country A is equal to the mean total amount spent by customers in country B.\n",
        "- Alternative Hypothesis (HA): The mean total amount spent by customers in country A is not equal to the mean total amount spent by customers in country B."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create two groups\n",
        "group1 = dataset[dataset[\"Country\"] == \"United Kingdom\"][\"TotalAmount\"]\n",
        "group2 = dataset[dataset[\"Country\"] == \"France\"][\"TotalAmount\"]\n",
        "\n",
        "# Perform two-sample t-test\n",
        "result = stats.ttest_ind(group1, group2)\n",
        "\n",
        "# Interpret result\n",
        "if result.pvalue < 0.05:\n",
        "    print(\"We reject the null hypothesis and accept the alternative hypothesis. The mean total amount spent by customers in United Kingdom is different from the mean total amount spent by customers in France.\")\n",
        "else:\n",
        "    print(\"We accept null hypothesis and reject alternate hypothesis. The mean total amount spent by customers in United Kingdom is equal to the mean total amount spent by customers in France.\")\n",
        "    \n",
        "# Print t-statistic and p-value\n",
        "print(\"t-statistic:\", result.statistic)\n",
        "print(\"p-value:\", result.pvalue)"
      ],
      "metadata": {
        "id": "vXmSQrEuWEcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A negative t-statistic indicates that the mean total amount spent by customers in the United Kingdom is lower than the mean total amount spent by customers in France.\n",
        "- However in this case, the p-value is greater than 0.05, indicating that we do not have sufficient evidence to reject the null hypothesis, and we cannot conclude that there is a significant difference between the means of the two groups."
      ],
      "metadata": {
        "id": "nJlBfIr5ZpC3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The statistical test used in this code is a two-sample t-test. We use this test to determine if there is a significant difference between the means of two independent groups."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We chose this test because we want to compare the mean total amount spent by customers in two different countries. The t-test is appropriate for this situation since we are comparing the means of two independent groups and assuming that the data is normally distributed. "
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We had missing values in customer id and description.\n",
        "- Randomly assigning Customer IDs can make it difficult to track customer behavior over time, such as their purchase history, preferences, and interactions with the company. This can make it challenging to personalize the customer experience and provide targeted marketing and promotional campaigns.\n",
        "- This is why though we had aroud 25% missing values, but instead of imputing based on business goal it was better to remove them for now."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "f-ddfWXebrHL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "t1jt5rXybrHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "\n",
        "# InvoiceNo starting with 'C' represents cancellation\n",
        "dataset['InvoiceNo'] = dataset['InvoiceNo'].astype('str')\n",
        "cancellations = dataset[dataset['InvoiceNo'].str.contains('C')]\n",
        "cancellations.head()"
      ],
      "metadata": {
        "id": "VZrEXQrubrHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping cancellations from the main dataframe\n",
        "df = dataset[~dataset['InvoiceNo'].str.contains('C')]"
      ],
      "metadata": {
        "id": "XFFbidJhbrHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- When analyzing customer behavior, it is important to focus on the customers who have made purchases and are likely to make future purchases, rather than those who have returned or cancelled their orders.\n",
        "- Additionally, including data from returned or cancelled orders could skew the analysis by including customers who may not be interested in the products or services offered by the business or may have had a negative experience with their previous purchase."
      ],
      "metadata": {
        "id": "uMvCCyYLUizP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "OJlza52PbrHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "\n",
        "# Adding 1 day to the Last Invoice date to set as Latest date for reference\n",
        "LatestDate = df[\"InvoiceDate\"].max() + pd.DateOffset(days=1)\n",
        "\n",
        "# Creating a new dataframe to calculate Recency, Frequency and Monetary scores for each customer\n",
        "rfm = df.groupby('CustomerID').agg({'InvoiceDate': lambda x: (LatestDate - x.max()).days,\n",
        "                                    'InvoiceNo': lambda x: len(x), 'TotalAmount': lambda x: x.sum()})\n",
        "\n",
        "# Renaming the columns\n",
        "rfm.rename(columns={'InvoiceDate': 'Recency', 'InvoiceNo': 'Frequency',\n",
        "                    'TotalAmount': 'Monetary'}, inplace=True)\n",
        "\n",
        "# Checking top 5 rows\n",
        "rfm.reset_index().head()"
      ],
      "metadata": {
        "id": "XS7kwREibrHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "XLsx9C2bbrHM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In the given scenario, the reason for removing the original features and adding the new features is not related to any specific feature selection method. Instead, it is based on domain knowledge and understanding of the problem, as well as the availability and quality of the data. \n",
        "- The new columns of customer ID, recency, frequency, and monetary may have been added as they are more relevant and informative for customer segmentation and analysis than the original features."
      ],
      "metadata": {
        "id": "KH6ZL2eZbrHM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "EBDwKO9LbrHM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Features which we removed** - \n",
        "\n",
        "- **Invoice No, Stock Code, Description, Quantity, Invoice Date, Unit Price, and Country**:\n",
        "\n",
        " These columns contain transactional details that are not directly related to customer behavior. In other words, they provide information about what customers purchased and when, but not about how often or how much they spent. Therefore, they are less useful for customer segmentation.\n",
        "\n",
        "**Selected Features** - \n",
        "\n",
        "- **Customer ID**: This column is still relevant as it identifies individual customers. However, it is not sufficient for customer segmentation because it does not provide any information about their behavior.\n",
        "\n",
        "- **Recency**: This new column indicates how recently a customer made a purchase. It is a useful metric for identifying customers who are more likely to make another purchase soon, as well as those who may have lost interest in the company's products.\n",
        "\n",
        "- **Frequency**: This new column indicates how often a customer makes a purchase. It is a useful metric for identifying loyal customers who are more likely to make repeat purchases.\n",
        "\n",
        "- **Monetary**: This new column indicates how much a customer spent on purchases. It is a useful metric for identifying high-value customers who are worth more to the company in terms of revenue."
      ],
      "metadata": {
        "id": "jg5_xDAybrHN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "\n",
        "# Outlier Analysis of Recency Frequency and Monetary\n",
        "\n",
        "attributes = ['Recency','Frequency','Monetary']\n",
        "plt.rcParams['figure.figsize'] = [8,5]\n",
        "sns.boxplot(data = rfm[attributes], orient=\"v\", palette=\"Set2\" ,whis=1.5,saturation=1, width=0.7)\n",
        "plt.title(\"Outliers Variable Distribution\", fontsize = 14, fontweight = 'bold')\n",
        "plt.ylabel(\"Range\", fontweight = 'bold')\n",
        "plt.xlabel(\"Attributes\", fontweight = 'bold')"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing (statistical) outliers for Monetary\n",
        "Q1 = rfm.Monetary.quantile(0.05)\n",
        "Q3 = rfm.Monetary.quantile(0.95)\n",
        "IQR = Q3 - Q1\n",
        "rfm = rfm[(rfm.Monetary >= Q1 - 1.5*IQR) & (rfm.Monetary <= Q3 + 1.5*IQR)]\n",
        "\n",
        "# Removing (statistical) outliers for Recency\n",
        "Q1 = rfm.Recency.quantile(0.05)\n",
        "Q3 = rfm.Recency.quantile(0.95)\n",
        "IQR = Q3 - Q1\n",
        "rfm = rfm[(rfm.Recency >= Q1 - 1.5*IQR) & (rfm.Recency <= Q3 + 1.5*IQR)]\n",
        "\n",
        "# Removing (statistical) outliers for Frequency\n",
        "Q1 = rfm.Frequency.quantile(0.05)\n",
        "Q3 = rfm.Frequency.quantile(0.95)\n",
        "IQR = Q3 - Q1\n",
        "rfm = rfm[(rfm.Frequency >= Q1 - 1.5*IQR) & (rfm.Frequency <= Q3 + 1.5*IQR)]"
      ],
      "metadata": {
        "id": "OupF1eLNcY-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attributes = ['Recency','Frequency','Monetary']\n",
        "plt.rcParams['figure.figsize'] = [8,5]\n",
        "sns.boxplot(data = rfm[attributes], orient=\"v\", palette=\"Set2\" ,whis=1.5,saturation=1, width=0.7)\n",
        "plt.title(\"Outliers Variable Distribution\", fontsize = 14, fontweight = 'bold')\n",
        "plt.ylabel(\"Range\", fontweight = 'bold')\n",
        "plt.xlabel(\"Attributes\", fontweight = 'bold')"
      ],
      "metadata": {
        "id": "6U3qJrV_cnow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " - The **IQR method** is useful for removing outliers because it is robust to extreme values and does not make assumptions about the distribution of the data. This method can be particularly useful for data that is not normally distributed or has a high degree of skewness.\n",
        " - By applying the IQR method to the data, we can identify and remove data points that are likely to be outliers and may negatively impact the results of the analysis. This can help to improve the accuracy and reliability of our clustering algorithms."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "\n",
        "# Handling the zeroes in the dataframe to avoid error in transformations\n",
        "rfm.replace(0.0,1,inplace=True)\n",
        "\n",
        "# Applying Log transformation on columns for smoothening the distribution\n",
        "rfm['Recency_Log']   = rfm['Recency'].apply(np.log)\n",
        "rfm['Frequency_Log'] = rfm['Frequency'].apply(np.log)\n",
        "rfm['Monetary_Log']  = rfm['Monetary'].apply(np.log)\n",
        "rfm.head()"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the distributions before and after log transformation.\n",
        "target = ['Recency', 'Frequency',\t'Monetary', 'Recency_Log', 'Frequency_Log', 'Monetary_Log']\n",
        "plt.figure(figsize=(20,10), dpi=90)\n",
        "for n,col in enumerate(target):\n",
        "  plt.subplot(2, 3, n+1)\n",
        "  sns.distplot(rfm[col])\n",
        "  plt.title(col.title())\n",
        "  plt.tight_layout()"
      ],
      "metadata": {
        "id": "1LjEF7uLdONI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Applying a logarithmic transformation (np.log) helps to normalize the data and reduce the impact of outliers.\n",
        "- The logarithmic transformation is commonly used when dealing with highly skewed data as skewed data can negatively impact the performance of clustering algorithms such as K-means.\n",
        "- In the case of RFM (Recency, Frequency, and Monetary), applying the logarithmic transformation can help to normalize the data and reduce the impact of extreme values."
      ],
      "metadata": {
        "id": "vJx57R748zjZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "\n",
        "# Defining X Variables\n",
        "X= rfm.iloc[:,3:6]\n",
        "X_scaled = StandardScaler().fit_transform(X)"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "id": "Lwqc5MXOsdw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfm_scaled = pd.DataFrame(X_scaled)\n",
        "rfm_scaled.columns = ['Recency', 'Frequency', 'Monetary']\n",
        "rfm_scaled"
      ],
      "metadata": {
        "id": "rzLXjO7-eLUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We have used Standard scaler for scaling data because it scales the data to have a mean of 0 and a standard deviation of 1. This helps to normalize the data and makes it easier to compare the relative importance of each feature.\n",
        "- In the case of RFM (Recency, Frequency, and Monetary), these three KPIs are likely to be measured using different units, scales, and ranges.By applying the standard scaler to these features, we can bring them to a common scale and ensure that they are equally weighted when calculating the distance between data points."
      ],
      "metadata": {
        "id": "eMSUczXkdleb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Elbow-curve/SSD\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "inertia_values = []\n",
        "for k in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(rfm_scaled)\n",
        "    inertia_values.append(kmeans.inertia_)\n",
        "\n",
        "plt.plot(range(1, 11), inertia_values, marker='o')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Inertia')\n",
        "plt.title('Elbow Method')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hbrJFMpZmcyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a simple vanillae model with 2 clusters\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Create a KMeans model with five clusters\n",
        "kmeans = KMeans(n_clusters=2, random_state=42)\n",
        "\n",
        "# Fit the KMeans model to the data\n",
        "kmeans.fit(rfm_scaled)\n",
        "\n",
        "y_kmeans = kmeans.fit_predict(X)"
      ],
      "metadata": {
        "id": "SpV95xt7WS-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7CluvgYduCJp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ML Model - K Means**\n",
        "\n",
        "- KMeans is an unsupervised machine learning algorithm used for clustering. It groups similar data points into clusters based on their distance from a centroid.\n",
        "\n",
        "**Evaluation Metrics**\n",
        "- The **silhouette score** is a metric that measures how similar an object is to its own cluster compared to other clusters. A higher silhouette score indicates that the clusters are well-separated and each data point belongs to the right cluster. Conversely, a lower silhouette score suggests that the data points may be assigned to the wrong clusters.\n",
        "- The **Calinski-Harabasz** index (also known as the Variance Ratio Criterion) is a measure of the ratio between the within-cluster dispersion and the between-cluster dispersion. A higher Calinski-Harabasz score indicates better defined clusters that are well separated from each other.\n",
        "- The **Davies-Bouldin index (DBI)** is another metric that can be used to evaluate the quality of clustering results. The DBI measures the average similarity between each cluster and its most similar cluster, with lower values indicating better clustering results."
      ],
      "metadata": {
        "id": "ihzg_J_sydFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "simple_kmeans_silhouette = silhouette_score(rfm_scaled, kmeans.fit_predict(rfm_scaled))\n",
        "simple_kmeans_calinski_harabasz_score = calinski_harabasz_score(rfm_scaled, kmeans.fit_predict(rfm_scaled))\n",
        "simple_kmeans_davies_bouldin_score = davies_bouldin_score(rfm_scaled, kmeans.fit_predict(rfm_scaled))\n",
        "\n",
        "print(\"Silhouette score for simple KMeans model:\", simple_kmeans_silhouette)\n",
        "print(\"Calinski Harabasz score for simple KMeans model:\", simple_kmeans_calinski_harabasz_score)\n",
        "print(\"Davies Bouldin score for simple KMeans model:\", simple_kmeans_davies_bouldin_score)"
      ],
      "metadata": {
        "id": "Z1asM0yDn1wS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Assign colors to the clusters\n",
        "colors = ['b', 'g']\n",
        "\n",
        "# Create a 3D plot\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Plot the data points with color based on their cluster label\n",
        "for i in range(len(kmeans.labels_)):\n",
        "    label = kmeans.labels_[i]\n",
        "    ax.scatter(rfm_scaled.iloc[i,0], rfm_scaled.iloc[i,1], rfm_scaled.iloc[i,2], color=colors[label])\n",
        "\n",
        "# Plot the centroids of the clusters\n",
        "ax.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], kmeans.cluster_centers_[:,2], marker='x', s=300, linewidths=3, color='red')\n",
        "\n",
        "# Set the properties of the plot\n",
        "ax.set_xlabel('Recency')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.set_zlabel('Monetary')\n",
        "ax.set_title('3D Visualization of Clusters Created by Simple KMeans Model')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HK3UMUWQfcA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "lKRnXtYjw2Y5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter tuning using GridSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters = {\n",
        "    'n_clusters': [2, 3, 4, 5],\n",
        "    'init': ['k-means++', 'random'],\n",
        "    'n_init': [10, 20, 30],\n",
        "    'max_iter': [100, 200, 300]}\n",
        "kmeans = KMeans(random_state=42)\n",
        "clf = GridSearchCV(kmeans, parameters, cv=5)\n",
        "clf.fit(rfm_scaled)\n",
        "\n",
        "# Instantiate KMeans model with best hyperparameters\n",
        "tuned_kmeans_model = KMeans(n_clusters=clf.best_params_['n_clusters'], random_state=42)\n",
        "tuned_kmeans_model.fit(rfm_scaled)\n",
        "\n",
        "# predicting model\n",
        "y_best_kmeans = tuned_kmeans_model.fit_predict(X)"
      ],
      "metadata": {
        "id": "t5dY8R89jmPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"Finally chosen parameters: \", grid_search.best_params_)\n",
        "\n",
        "print(\"Finally chosen parameters: \", clf.best_params_)"
      ],
      "metadata": {
        "id": "BIyvM8fYmTOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "n1P39t5OxpB7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We used **GridSearchCV** because number of hyperparameters to tune is few, and it can search through all possible combinations of hyperparameters, which can lead to finding the optimal combination."
      ],
      "metadata": {
        "id": "RvUuIuz5Ayzs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The hyperparameters that were finally chosen for the KMeans clustering algorithm were - \n",
        "\n",
        "- **'init': 'k-means++'**: This specifies the method for initialization of the centroids. 'k-means++' is a smart initialization method that attempts to select initial centroids that are distant from each other, in order to improve the quality of the final clustering result.\n",
        "\n",
        "- **'max_iter': 100**: This specifies the maximum number of iterations for each run of the KMeans algorithm. If the algorithm does not converge within this number of iterations, it will stop and return the best result found so far.\n",
        "\n",
        "- **'n_clusters': 5**: This specifies the number of clusters to be formed by the algorithm. In your case, the chosen value is 5.\n",
        "\n",
        "- **'n_init': 10**: This specifies the number of times the KMeans algorithm will be run with different random initializations. The algorithm will return the result with the lowest SSE (sum of squared errors) among all the runs.\n",
        "\n",
        "\n",
        "So, in summary, the hyperparameters that were finally chosen for the KMeans clustering algorithm were selected using GridSearchCV and are intended to produce the best possible clustering results."
      ],
      "metadata": {
        "id": "ugX4NBv_xpB7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Y4xienGSx-kS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tuned KMeans model Silhoutte score\n",
        "\n",
        "tuned_kmeans_silhouette_score = silhouette_score(rfm_scaled, clf.best_estimator_.fit_predict(rfm_scaled))\n",
        "tuned_kmeans_calinski_harabasz_score = calinski_harabasz_score(rfm_scaled, clf.best_estimator_.fit_predict(rfm_scaled))\n",
        "tuned_kmeans_davies_bouldin_score = davies_bouldin_score(rfm_scaled, clf.best_estimator_.fit_predict(rfm_scaled))\n",
        "\n",
        "\n",
        "print(\"Silhouette score for hyperparameter-tuned KMeans model:\", tuned_kmeans_silhouette_score)\n",
        "print(\"Calinski Harabasz score for hyperparameter-tuned KMeans model:\", tuned_kmeans_calinski_harabasz_score)\n",
        "print(\"Davies Bouldin score for hyperparameter-tuned KMeans model:\", tuned_kmeans_davies_bouldin_score)"
      ],
      "metadata": {
        "id": "_VtpQhblpK3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing clusters along with their centroids\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Assign colors to the clusters\n",
        "colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k']\n",
        "\n",
        "# Create a 3D plot\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Plot the data points with color based on their cluster label\n",
        "for i in range(len(clf.best_estimator_.labels_)):\n",
        "    label = clf.best_estimator_.labels_[i]\n",
        "    ax.scatter(rfm_scaled.iloc[i,0], rfm_scaled.iloc[i,1], rfm_scaled.iloc[i,2], color=colors[label])\n",
        "\n",
        "# Plot the centroids of the clusters\n",
        "ax.scatter(clf.best_estimator_.cluster_centers_[:,0], clf.best_estimator_.cluster_centers_[:,1], clf.best_estimator_.cluster_centers_[:,2], marker='x', s=300, linewidths=3, color='red')\n",
        "\n",
        "# Set the properties of the plot\n",
        "ax.set_xlabel('Recency')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.set_zlabel('Monetary')\n",
        "ax.set_title('3D Visualization of Clusters Created by Simple KMeans Model')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tAldDRvZjmS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = {'Silhouette': [silhouette_score(rfm_scaled, y_kmeans), silhouette_score(rfm_scaled, y_best_kmeans)],\n",
        "           'Davies-Bouldin': [davies_bouldin_score(rfm_scaled, y_kmeans), davies_bouldin_score(rfm_scaled, y_best_kmeans)],\n",
        "           'Calinski-Harabasz': [calinski_harabasz_score(rfm_scaled, y_kmeans), calinski_harabasz_score(rfm_scaled, y_best_kmeans)]}\n",
        "\n",
        "df_metrics = pd.DataFrame(metrics, index=['Random K-Means', 'Tuned K-Means'])\n",
        "df_metrics.head()"
      ],
      "metadata": {
        "id": "_4p8KwXLiWiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In our case,all the three mertics are indicating better clustering in simple k means model. This means that the simple KMeans model is better at separating the customer data into distinct clusters, while the hyperparameter-tuned KMeans model may not be as effective at clustering the data.\n",
        "\n",
        "- However, it's important to note that the choice of the best model depends on other factors as well, such as the problem you're trying to solve, the size of the dataset, and the interpretability of the results. So, even though the simple KMeans model has a higher silhouette score, it may not always be the best choice for clustering the data."
      ],
      "metadata": {
        "id": "Ap1xURwutKKu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose the number of clusters\n",
        "n_clusters = 4\n",
        "\n",
        "# Choose the distance metric and linkage method\n",
        "distance_metric = 'euclidean'\n",
        "linkage_method = 'ward'\n",
        "\n",
        "# Fit the hierarchical clustering model\n",
        "model = AgglomerativeClustering(n_clusters=n_clusters, affinity=distance_metric, linkage=linkage_method)\n",
        "model.fit(X)\n",
        "\n",
        "#Perdicting model\n",
        "y_model = model.fit_predict(X)\n"
      ],
      "metadata": {
        "id": "xADuPNrDxbLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ML Model - Hierarchical Clustering**\n",
        "\n",
        "- Hierarchical clustering is a type of clustering algorithm used in machine learning and data analysis that groups similar data points into clusters based on their distance or similarity to each other.\n",
        "- The choice of distance metric and linkage criterion determines the performance and effectiveness of hierarchical clustering. Popular distance metrics include Euclidean distance, Manhattan distance, and cosine distance. Linkage criteria include single linkage, complete linkage, and average linkage.\n",
        "- There are two types of hierarchical clustering:\n",
        "\n",
        "   - Agglomerative hierarchical clustering: This starts with each data point as a separate cluster and then merges the closest pairs of clusters iteratively until all the points belong to a single cluster.\n",
        "\n",
        "   - Divisive hierarchical clustering: This starts with all the data points in a single cluster and then recursively splits the cluster into smaller clusters until each point is in its own cluster.\n",
        "\n",
        "**Evaluation Metrics**\n",
        "- The **silhouette score** is a metric that measures how similar an object is to its own cluster compared to other clusters. A higher silhouette score indicates that the clusters are well-separated and each data point belongs to the right cluster. Conversely, a lower silhouette score suggests that the data points may be assigned to the wrong clusters.\n",
        "- The **Calinski-Harabasz** index (also known as the Variance Ratio Criterion) is a measure of the ratio between the within-cluster dispersion and the between-cluster dispersion. A higher Calinski-Harabasz score indicates better defined clusters that are well separated from each other.\n",
        "- The **Davies-Bouldin index (DBI)** is another metric that can be used to evaluate the quality of clustering results. The DBI measures the average similarity between each cluster and its most similar cluster, with lower values indicating better clustering results."
      ],
      "metadata": {
        "id": "2rzt8A7j-ARb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the metrics\n",
        "silhouette = silhouette_score(X, model.labels_)\n",
        "calinski_harabasz = calinski_harabasz_score(X, model.labels_)\n",
        "davies_bouldin = davies_bouldin_score(X, model.labels_)\n",
        "\n",
        "print(\"Silhouette score for simple hierarchical_clustering_ model:\", silhouette)\n",
        "print(\"Calinski Harabasz score for simple hierarchical_clustering_ model:\", calinski_harabasz)\n",
        "print(\"Davies Bouldin score for simple hierarchical_clustering_ model:\", davies_bouldin)"
      ],
      "metadata": {
        "id": "mlxxMNUs_QzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the clusters in 3D view\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(X['Recency_Log'], X['Frequency_Log'], X['Monetary_Log'], c=model.labels_,cmap='plasma')\n",
        "ax.set_xlabel('Recency')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.set_zlabel('Monetary')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QvtqvfhX_RAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tune the hyperparameters using GridSearchCV\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Set up the hyperparameter grid for the model\n",
        "param_grid = {\n",
        "    'n_clusters': [2, 3, 4, 5],\n",
        "    'affinity': ['euclidean', 'manhattan', 'cosine'],\n",
        "    'linkage': ['ward', 'complete', 'average']\n",
        "}\n",
        "\n",
        "# Choose the scoring metric for hyperparameter tuning\n",
        "from sklearn.metrics import make_scorer\n",
        "scorer = make_scorer(silhouette_score, greater_is_better=True)\n",
        "\n",
        "# Set up the grid search cross-validation\n",
        "model = AgglomerativeClustering()\n",
        "grid_search = GridSearchCV(model, param_grid=param_grid, scoring=scorer)\n",
        "grid_search.fit(X)\n",
        "best_params = grid_search.best_params_\n",
        "best_hierarchy = grid_search.best_estimator_\n",
        "y_best_hierarchy = best_hierarchy.fit_predict(X)"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Finally chosen parameters: \", grid_search.best_params_)"
      ],
      "metadata": {
        "id": "MoNlFmc9_ycu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We used **GridSearchCV** because number of hyperparameters to tune is few, and it can search through all possible combinations of hyperparameters, which can lead to finding the optimal combination."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chosen hyperparameters are specific settings for a clustering algorithm, where:\n",
        "\n",
        "- **'affinity'**: This parameter specifies the distance metric to be used in the clustering algorithm. In this case, the 'euclidean' distance metric is used for clustering algorithms to measure the similarity between data points.\n",
        "\n",
        "- **'linkage'**: This parameter specifies the criterion used to measure the distance between clusters during the clustering process. In this case, the 'ward' criterion to minimizes the variance of the distances between the clusters being merged.\n",
        "\n",
        "- **'n_clusters'**: This parameter specifies the number of clusters to be formed by the algorithm. In this case, the algorithm will form 2 clusters.\n",
        "\n",
        "\n",
        "So, in summary, the hyperparameters that were finally chosen for the Hierarchical clustering algorithm were selected using GridSearchCV and are intended to produce the best possible clustering results."
      ],
      "metadata": {
        "id": "bR--CE4eBOjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tuned hierarchical_cluster model Silhoutte score\n",
        "\n",
        "tuned_hierarchical_cluster_silhouette_score = silhouette_score(X, grid_search.best_estimator_.fit_predict(X))\n",
        "tuned_hierarchical_cluster_calinski_harabasz_score = calinski_harabasz_score(X, grid_search.best_estimator_.fit_predict(X))\n",
        "tuned_hierarchical_cluster_davies_bouldin_score = davies_bouldin_score(X, grid_search.best_estimator_.fit_predict(X))\n",
        "\n",
        "\n",
        "print(\"Silhouette score for hyperparameter tuned hierarchical cluster model:\", tuned_hierarchical_cluster_silhouette_score)\n",
        "print(\"Calinski Harabasz score for hyperparameter tuned hierarchical cluster model:\", tuned_hierarchical_cluster_calinski_harabasz_score)\n",
        "print(\"Davies Bouldin score for hyperparameter tuned hierarchical cluster model:\", tuned_hierarchical_cluster_davies_bouldin_score)"
      ],
      "metadata": {
        "id": "ffFRYREGDMNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing clusters along with their centroids\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Assign colors to the clusters\n",
        "colors = ['b', 'g']\n",
        "\n",
        "# Create a 3D plot\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Plot the data points with color based on their cluster label\n",
        "for i in range(len(grid_search.best_estimator_.labels_)):\n",
        "    label = grid_search.best_estimator_.labels_[i]\n",
        "    ax.scatter(rfm_scaled.iloc[i,0], rfm_scaled.iloc[i,1], rfm_scaled.iloc[i,2], color=colors[label])\n",
        "\n",
        "# Set the properties of the plot\n",
        "ax.set_xlabel('Recency')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.set_zlabel('Monetary')\n",
        "ax.set_title('3D Visualization of Clusters Created by Simple KMeans Model')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KLPf5bfDDTX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = {'Silhouette': [silhouette_score(X, y_model), silhouette_score(X, y_best_hierarchy)],\n",
        "           'Davies-Bouldin': [davies_bouldin_score(X, y_model), davies_bouldin_score(X, y_best_hierarchy)],\n",
        "           'Calinski-Harabasz': [calinski_harabasz_score(X, y_model), calinski_harabasz_score(X, y_best_hierarchy)]}\n",
        "\n",
        "df_metrics = pd.DataFrame(metrics, index=['Random Hierarchical Clustering', 'Tuned Hierarchical Clustering'])\n",
        "df_metrics.head()"
      ],
      "metadata": {
        "id": "nk28Hlx8Dbcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  Tuned hierarchical clustering algorithm performs better than the random hierarchical clustering algorithm based on all three metrics, indicating that it is a better choice for clustering the data.\n",
        "- However, it's important to note that the choice of the best model depends on other factors as well, such as the problem you're trying to solve, the size of the dataset, and the interpretability of the results. So, even though the Tuned Hierarchical Clustering Model has a higher silhouette score, it may not always be the best choice for clustering the data."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact of the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Metric's indication towards business**\n",
        "- A high Silhouette score means that the clustering model can effectively segment the customer base into distinct groups based on their RFM values.\n",
        "- A low Davies-Bouldin index means that the clustering model can create well-defined and well-separated clusters that can be easily interpreted by the business.\n",
        "- A high Calinski-Harabasz index means that the clustering model can create clusters that are well-separated and distinct from each other, and that the variance between clusters is large compared to the variance within clusters. This can help businesses to identify the most valuable customer segments and allocate their resources to maximize revenue and profitability.\n",
        "\n",
        "\n",
        "**Impact of hierarchical clustering model on RFM analysis**\n",
        "- Hierarchical clustering can provide businesses with a powerful tool for customer segmentation and analysis. By using this method to group customers based on RFM values, businesses can gain a deeper understanding of their customer base and develop data-driven strategies to improve customer engagement, loyalty, and profitability."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- It's generally recommended to use a combination of objective metrics and subjective judgment to evaluate the performance of a clustering model.\n",
        "- Objective metrics can provide a quantitative measure while subjective judgment can provide a qualitative assessment of the results based on domain knowledge. This combined approach can help to ensure a comprehensive and well-informed evaluation of the model's performance."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given these metrics, we can say that the Calinski-Harabasz index has the most positive business impact for the tuned K-Means model. A high Calinski-Harabasz index indicates that the clusters are well-separated and distinct, and that the variance between clusters is large compared to the variance within clusters. This can help businesses to identify the most valuable customer segments and allocate their resources to maximize revenue and profitability."
      ],
      "metadata": {
        "id": "ikfoL-Q3J7az"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameter Tuned K-Means Clustering Model**\n",
        "\n",
        "- It's not uncommon for clustering models with fewer clusters to have higher Silhouette scores compared to models with more clusters. This is because having fewer clusters can result in more distinct and well-separated clusters, leading to a higher Silhouette score. However, the number of clusters should ultimately be determined by the business objectives and the insights you are trying to extract from the data.\n",
        "- While the simple k means model with 2 clusters has a higher Silhouette score,but the hyperparameter tuned k means model with 5 clusters looks better on visualization, indicating more distinct and well-separated clusters. Moreover it aligns better with our business objective of wide customer segmentation.\n",
        "- It is worth sacrificing a slightly lower Silhouette score for the benefits of having more clusters. More clusters can provide a more granular view of the data, enabling more targeted and specific marketing strategies. \n",
        "- Moreover visualizations of the clusters indicate a clear separation of customer groups, which indicates that the clustering model is effective in segmenting the customer base."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap"
      ],
      "metadata": {
        "id": "4fy_HMfxr7_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SHAP analysis\n",
        "import shap\n",
        "\n",
        "background_data = shap.sample(X, 100)\n",
        "explainer = shap.KernelExplainer(tuned_kmeans_model.predict, background_data)\n",
        "shap_values = explainer.shap_values(X)\n",
        "\n",
        "# Visualize SHAP values\n",
        "shap.summary_plot(shap_values, X, plot_type=\"bar\")"
      ],
      "metadata": {
        "id": "9C6YqlfF13nz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The magnitude of the SHAP value represents the strength of the impact of that feature on the model's prediction.\n",
        "- In summary, based on the output it appears that recency has the strongest impact on the model's predictions, followed by frequency and monetary."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File\n",
        "\n",
        "import pickle\n",
        "with open('tuned_kmeans_model.pkl', 'wb') as f:\n",
        "    pickle.dump(kmeans, f)"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File\n",
        "import pickle\n",
        "with open('tuned_kmeans_model.pkl', 'wb') as f:\n",
        "    pickle.dump(tuned_kmeans_model, f)"
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data.\n",
        "with open('tuned_kmeans_model.pkl', 'rb') as f:\n",
        "    kmeans_loaded = pickle.load(f)"
      ],
      "metadata": {
        "id": "VkiSsVKyFeuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the loaded model to predict unseen data.\n",
        "X_test = np.array([[100, 50, 100],[1, 5, 1],[20, 35, 70], [100, 50, 100],[5, 10, 200]])\n",
        "y_pred = kmeans_loaded.predict(X_test)\n",
        "# Print the predicted labels\n",
        "print(y_pred)"
      ],
      "metadata": {
        "id": "FJlycn0UK8EW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}